用于构建实时数据管道和流应用，具有水平扩展性，容错性，邪恶的快。发布订阅的消息系统，实时有效的流数据，安全地分布式复制集群。

简介，Kafka是一个分布式流平台。流平台应具有三种关键能力，可以发布订阅记录流，与消息队列或企业消息系统类似。可以以具有容错性的方式存储记录流。可以处理记录流当它们发生时。

kafka主要用于两广泛类应用，在系统或应用间构建可靠的实时流数据管道。构建实时流应用来转换或响应数据流。

kafka运行于集群模式，集群以topic来区分存储记录流，每个记录由键、值和时间戳组成。

kafka有四种核心API，生产者，允许一个应用发布一到多个topic的记录流。消费者，允许一个应用订阅一到多个topic和处理向它们出示的记录流。流，允许一个应用充当一个流处理器，从一到多个topic消费一个输入流，产生一个输出流到一到多个输出topic，有效地转换输入流到输出流。连接器，允许构建和运行可重复使用的生产者或消费者连接kafka的topic到已存在的应用或数据系统，例如，一个到关系数据库的连接器可以捕获一个表的每次改变。

kafka里客户端和服务器端的通信是采用一个简单、高性能和语言无关的TCP协议。协议具有版本且维护对旧版本的向后兼容。

topic和log，kafka对一个记录流的核心抽象是-topic，topic是一个分类或供给名称，记录就发布给它。topic总是多订阅者，即一个topic可以有零到多个消费者订阅写向它的数据。对于每个topic，集群维护一个分区log，每个分区是一个有序的不可变的记录序列，且不断地在后面追加，是一个结构化的commit log，分区中的每个记录都被分配一个连续的id号，叫做offset（偏移量）唯一地标识分区中的一条记录。

kafka集群保留所有发布的记录，无论它们是否已经被消费，保留周期的时长是可配置的。如果保留策略设置为两天，记录发布后的两天内都可以被消费，超期后就会被丢弃来释放空间。kafka的性能在对于数据量大小方面来说永远是高效的，所以存储长时间的数据不是问题。

事实上，每个消费者上仅仅保留的元数据是这个消费者在log中的偏移量或位置，偏移量被消费者控制，通常一个消费者将线性推进它的偏移量当它读记录时，但是，事实上，消费者可以以任何它喜欢的顺序来消费记录，所以偏移量的变化不一定是线性增长的。消费者可以重新复位到一个旧的偏移量重新处理过去的数据，或向前跳至最近的记录，从现在开始消费。

kafka的消费者非常cheap，它们来和去在集群上或其它消费者上没有太多冲撞，每个人消费自己的，互不影响。

日志中的分区有几个目的，首先，它允许log在单个服务器上扩展到适合大小，每个分区必须适合装载它的服务器，一个topic可以有很多分区，所以可以处理任意数量的数据。其次，它充当并行的单元，分区之间并行消费，互不影响。

日志的分区是分布在kafka集群中的服务器上的，每个服务器为一个多分区的共享处理数据和请求。每个分区重复一定的数目用于容错性，该数目可配置。在重复分区中，其中一个分区所在服务器充当leader，其余的零到多个服务器充当followers，leader处理对该分区的所有读写请求，而followers被动地复制leader的数据但不处理任何请求，如果leader失败，followers中的一个将自动变为新的leader，一个服务器对存储在它上面的所有分区中的一些分区充当leader，对剩余的分区充当follower，所以集群中的负载很好地平衡了。

生产者，生产者发布数据到它们选择的topic，生产者承担哪个记录分配给topic中的哪个分区。可以使用简单的轮询的方式达到负载均衡，或基于某个语义分区函数（如基于记录中的某个key来选择分区）。

消费者，消费者用一个消费者组名称来标记自己，发布到一个topic里的每个记录，被分发到每个订阅的消费者组中的一个消费者实例。消费者实例可以在不同的进程里或不同的机器上。如果所有的消费者实例都有相同的消费者组名称，记录将在所有的消费者实例上有效地负载均衡。如果所有的消费者实例的组名都不相同，这时每条记录将广播到所有的消费者实例。

通常情况下发现，所有topic都有很少的消费者组，每个消费者组在逻辑上作为一个订阅者，每个消费者组有许多消费者实例组成用于扩展性和容错性。这并没有超越发布订阅语义，只不过订阅者是一个消费者集群而不是单个消费者。

kafka中消费方式的实现是在所有的消费者实例上来分割log中的所有分区，所以任何时候每个实例是所有分区的一个公平共享的排它消费者。这种组内维护成员关系的过程被kafka协议动态处理。如果新实例加入到组将从组内的其它成员那接任一些分区，如果一个实例挂了，它的分区将分发给剩余的实例。

kafka只提供一个分区里面记录的总顺序，同一个topic的不同分区间无法做到。对于分区数据来说，每个分区顺序联合的能力通过key来实现对大多数应用是足够的。如果想要一个topic的所有的记录的一个总顺序，这时一个topic只能有一个分区，同时一个消费者组里只能有一个消费者实例。

保证，kafka在一个高级别提供一下保证，一个生产者发送给一个特定topic分区的所有消息将以它们被发送的顺序追加到后面。先发送记录1再发送记录2，那么在log的分区中记录1偏移量小且先出现。一个消费者以log中记录存储的顺序查看它们。对于一个具有复制因子为N的topic，我们将容忍最多N-1个服务器失败而不会丢失log中的任何已提交记录。

作为一个消息系统，kafka的流概念如何和传统企业的消息系统比较。传统消息有两类模型，队列和发布订阅。在队列模式中，一个消费者池中的所有消费者可以从一个服务器上读数据，每个记录最终到其中一个消费者。在发布订阅模式中，每个记录将广播给所有的消费者，即每个消费者都会消费所有的记录。每个模型都有自己的长处和不足。队列模型的长处是允许在多个消费者实例上分割对数据的处理，这样可以扩展处理能力。不幸的是，队列不是多订阅者的，一旦一个消费者读取了数据，数据就不存在了。发布订阅允许广播数据到多个消费者，但是没有办法处理扩展能力，因为每条消息到每个订阅者。

kafka中消费者组的概念泛化为两个概念。对于一个队列，消费者组就是一个消费者的集合，在它上面分割对数据的处理。对于发布订阅，允许广播数据到多个消费者组。kafka模型的优势是每个topic都有以上两个属性，能够扩展处理能力，同时也是多订阅者的。且比传统的消息系统具有更强的顺序保证。

在传统的队列中，记录在服务器上的存储是有序的，多个消费者从队列消费时，服务器以记录存储的顺序交出记录，但是记录是异步地分发给消费者的，所以当它们到达不同消费者时顺序将变乱。实际意味着在并行消费情况下记录顺序的丢失。消息系统通常使用一个概念来绕过这个问题，就是独占消费，只允许一个消费者从一个队列消费，不过同时并行消费也已经不存在了。

kafka做的更好，通过一个并行的概念--分区（在topic里）。能够同时提供顺序保证和负载均衡在一池消费者上。实现为把topic里的所有分区分配给消费者组中的所有消费者，以至于topic中的每个分区实际上被消费者组内的一个确定的消费者在消费。这样做我们能够确定这个消费者是那个分区唯一的消费者且顺序地消费数据。因为有许多分区，所以在许多消费者实例上任然可以均衡负载。注意，一个消费者组中的消费者数量不能比分区数目多。

作为一个存储系统，任何消息队列都允许发布消息和消费它们之间解耦，是在有效地为飞行中的消息充当一个存储系统。kafka的不同之处在于它是一个非常好的存储系统。数据写入kafka就是写入磁盘和重复备份用于容错性。kafka允许生产者等待回应，以至于一个写入操作不会被认为成功直到数据被复制备份和即使服务器写入失败也要保证持久化。磁盘结构kafka使用良好扩展，无论服务器上的数据量是KB还是TB，kafka的性能都是一样的好。

由于认知对待存储和允许客户端控制读取数据的位置，可以认为kafka是一类特殊目的的分布式文件系统，专用于高性能、低延时的commit log的存储、复制和传播。

用于流处理，仅仅读、写、存储数据流是不够的，目的是能够进行实时的流处理。kafka的一个流处理器是，可以从输入topic中消费连续不断的数据流，在这些数据流上执行一些操作处理，生产连续不断的数据流到输出topic。例如，一个零售应用可以消费销售和运输的输入流，生成根据这些数据计算的重新排序和价格调整的输出流。

可以直接使用生产者和消费者API做一些简单的处理，对于比较复杂的转换kafka提供一个完全集成的流API，这允许构建应用来做些有意义的处理，像从流上计算聚合或把流连接在一起。这种功能可以解决应用面对的这类型难题，处理无序数据、重新处理输入作为转码，执行有状态的计算。流API构建在kafka提供的核心基元上，生产者和消费者API用于输入，kafka用于有状态存储，相同的组机制用于在多个流处理器实例间容错。

把以上特性结合起来，把消息、存储和流处理结合起来或许看起来不寻常，但是它对kafka作为流处理平台的角色来说是必须的。一个分布式文件系统像HDFS允许存储静态文件用于大批量处理。实际上像这样的一个系统允许存储和处理过去的历史数据。一个传统的企业消息系统允许处理将来的消息就是在你订阅之后将收到。以这种方式构建的应用处理将来的数据当到达时。kafka把这些能力结合起来，这种结合对于kafka用作流应用的平台和流数据管道来说都是关键的。通过结合存储和低延时订阅，流应用能够以相同的方式对待过去和未来的数据。这是单个应用能够处理历史存储数据而不是当它到达最后一条数据就结束。这是流处理的一个泛化概念，包括批量处理和消息驱动应用。

同样地像流数据管道，把订阅和实时事件联合起来使kafka可以用于非常低延迟的管道。但可靠存储数据的能力使它可以用于关键数据，即数据的分发必须得到保证。或与离线系统集成，仅周期性地加载数据。或向下到时间的扩展周期用于维护。流处理功能使它能够转换数据当到达时。

用例
消息，替换传统的消息代理，消息代理的使用有很多原因（把数据的处理和生产分开，缓存未处理的消息），与大多数消息系统相比，kafka有更好的吞吐量，内建分区、复制和容错，使它成为大规模消息处理应用的一个好的解决方案。以我们的经验消息使用通常在一个相对较低的吞吐量，但是可能会要求比较小的端到端延时，经常依赖于kafka提供的强壮的持久化保证。

站点活动跟踪，原本用于能够重建一个用户活动跟踪管道，作为一个实时的发布订阅推送的集合。这意味着站点活动（页面访问，搜索，其它动作等）采用一个活动类型一个topic的形式被发送到中央topics。这些推送对于若干应用情况是可用的，包括实时处理、实时监控，加载到Hadoop，离线数据存储系统用于离线数据处理和报表。

度量，kafka经常用于运营监控数据，涉及从分布式应用聚合统计来产生运营数据的集中式的推送。

日志聚合，kafka可作为日志聚合方案的一个替代。日志聚合典型地从服务器收集物理日志文件，把它们放到一个核心的地方（文件服务器或HDFS）来处理。kafka抽象掉了文件的详细内容，给出日志的一个干净抽象，或事件数据作为一个消息流。这允许更低延时的处理和更容易地支持多数据源和分布式数据消费。与一般的log系统如Scribe或Flume相比，kafka提供同等的好性能，更强壮的持久化保证（采用复制备份），更低的端到端延时。

流处理，在由多个阶段组成的处理管道里面处理数据，原始的输入数据从kafka的topics消费，然后聚合、浓缩或其它的转化，然后进入新的topics用于进一步消费或跟踪处理。例如一个处理管道用于推荐新文章，可能从RSS订阅爬取文章内容，把它发布到一个topic，进一步的处理可能常规化，消除重复，把干净的文章内容发布到另一个新的topic，最终处理可能推荐这些文章给用户。这样的处理管道创建实时数据流动图基于单个的topic。一个轻量但强大的流处理库在kafka里被提供来执行像上面的那些数据处理。除了kafka之外还有Apache Storm和Apache Samza流处理工具。

事件源，事件源风格的应用设计为当状态改变时进行记录，产生以时间为顺序的一系列记录。kafka支持非常大量的日志存储，使它成为这类应用非常优秀的后台。

commit log，kafka可以服务于一个外部的commit log用于分布式系统，日志帮助在节点间复制进行备份，充当一个重同步机制用于失败的节点来重新存储它们的数据，日志压缩（合并）特性支持这种用法，这种用法与Apache BookKeeper相似。




Manual Partition Assignment
在上一个示例中，我们订阅感兴趣的topic，让kafka动态分配一个公平共享的分区用于这些topic，基于组内的活动消费者。有时需要细粒度地控制指定的分区来分配。
如果进程正在维护和分区有关的某种本地状态（像本地磁盘上的key-value存储），它应该仅仅从它在磁盘上维护的分区里获得记录。
如果进程本身是高可用的，失败时将被重启（或许使用一个集群管理框架像YARN、Mesos等）。这种情况不需要kafka来检测失败和重分配分区，因为消费进程将在其它机器上重启。
为了使用这种模式，可以调用assign(Collection)方法并指定一个完整的分区列表，你想从它们消费。
     String topic = "foo";
     TopicPartition partition0 = new TopicPartition(topic, 0);
     TopicPartition partition1 = new TopicPartition(topic, 1);
     consumer.assign(Arrays.asList(partition0, partition1));
一旦分配好，你可以在一个循环里调用poll方法，就可以像前面那样消费记录。消费者指定的组仍然用于提交偏移量，但是现在分区集合将只有在对assign方法的再次调用时才会改变。手动分区分配不使用组协调，因此消费者失败将不导致分区分配冲平衡。每个消费者具有独立的行为，即使它与另一个消费者共享一个组ID。为了避免偏移量提交冲突，你应该通常确保对于每一个消费者实例，组ID是唯一的。
注意，不能够把手动分区分配（使用assign方法）和动态分区分配（使用subscribe方法）混合在一起。
Storing Offsets Outside Kafka
消费者应用不需要使用kafka内建的偏移量存储，它可以存储偏移量到自己选择的存储中。主要使用场景是允许应用以原子的方式把偏移量和消费结果存储到同一个系统。这并不总是可行，但是当它可行时，它将使消费完全地原子的，给出"确切一次"语义比使用kafka的偏移量提交功能默认获得的"至少一次"的语义要强。
如果消费结果正被存储在一个关系数据库，把偏移量也存储到数据库，能够允许消费结果和偏移量在一个事务里提交。要么消费成功同时更新偏移量或者消费失败不更新偏移量。
如果消费结果正被存储到一个本地存储，也可以把偏移量存到那里。例如通过订阅一个特殊的分区能够创建一个搜索索引，偏移量和索引数据可以存储在一起。如果这是以原子方式完成的，通常这是可能的使它成为这种情况即使崩溃发生造成未同步的数据丢失，无论留下什么东西，相应的偏移量也会存储。。。
每个记录都有它自己的偏移量，因此要管理你自己的偏移量仅仅需要做下面这些。
配置enable.auto.commit=false，使用随ConsumerRecord提供的偏移量来存储你的位置，在重新启动时使用seek(TopicPartition, long)方法来重新存储消费者的位置。
这种用法类型最简单，当分区分配是手动完成时。如果分区分配是自动完成的，需要特别关注处理分区分配发送改变的情形。可以通过提供一个ConsumerRebalanceListener实例在对subscribe(Collection, ConsumerRebalanceListener)和subscribe(Pattern, ConsumerRebalanceListener)调用时。例如，当分区从一个消费者被带走时，消费者将希望为这些分区提交它的偏移量，通过实现ConsumerRebalanceListener.onPartitionsRevoked(Collection)来做到。当分区被分配给一个消费者时，消费者将希望为这些新分区查询偏移量，正确地初始化消费者到那个位置，通过实现ConsumerRebalanceListener.onPartitionsAssigned(Collection)来做到。
ConsumerRebalanceListener的另一个普通使用是来刷新应用程序为分区维护的任何缓存，移动到其它地方。
Controlling The Consumer's Position
大多使用情况是，消费者简单地消费记录从开头到结束，周期性地提交它的位置（要么自动，要么手动）。kafka允许消费者手动控制它的位置，在一个分区里面随意地向前或向后移动。这意味着一个消费者能够重消费旧的记录，或跳至最新的记录，没有实际消费中间的记录。
有几种情况手动控制消费者的位置非常有用。一种是用于时间敏感的记录处理，对于一个落后太远的消费者，不尝试去追上处理所有的记录，而是跳到最近的记录，它将是有意义的。
另一个用例是一个系统维护了本地状态。这种情况消费者希望在启动时把它的位置初始化为本地存储里面包含的内容。同样地如果本地状态被破坏，状态可能在一个新的机器上被重建，通过重消费所有的数据和重创建状态（假设kafka保留足够的历史）。
kafka允许使用seek(TopicPartition, long)方法指定位置来指定新的位置。特别的方法seekToBeginning(Collection)和seekToEnd(Collection)定位到服务器维护的最早和最近的偏移量也是可用的。
Consumption Flow Control
如果一个消费者被分配多个分区来从它们取数据，将尝试同时从它们消费数据，实际上这些分区具有相同的优先权。有时消费者希望首先关注某些分区并全速获取数据，当这些分区没有数据或有很少数据可消费时，才开始从其它分区获取数据。
一种使用场景是流处理，处理器从两个topic取数据并在这两个流上执行连接操作。当一个topic长时间地落后于另一个，处理器希望暂停从靠前的那个topic取数据，为了使落后的topic能够赶上。另一个例子是基于消费者启动的引导，在有许多历史数据需要追赶，应用通常希望获取某些topic的最新数据，在考虑获取其它topic之前。
kafka支持动态控制消费流程，通过使用pause(Collection)和resume(Collection)在指定的分区上暂停消费和在指定的已暂停分区上恢复消费，在将来的poll(long)调用中。
Multi-threaded Processing
kafka消费者不是线程安全的。所有的网络IO都在应用程序所在的线程里执行调用。用户有责任确保多线程访问被合适的同步。非同步的访问将导致ConcurrentModificationException。
对于这个规则唯一的例外是wakeup()，可以安全地从一个外部线程里使用来中断一个活动的操作。此时，一个WakeupException将从阻塞在这个操作上的线程里被抛出。这可以用于从另一个线程关闭消费者。下面代码片段给出典型的模式。
 public class KafkaConsumerRunner implements Runnable {
     private final AtomicBoolean closed = new AtomicBoolean(false);
     private final KafkaConsumer consumer;

     public void run() {
         try {
             consumer.subscribe(Arrays.asList("topic"));
             while (!closed.get()) {
                 ConsumerRecords records = consumer.poll(10000);
                 // Handle new records
             }
         } catch (WakeupException e) {
             // Ignore exception if closing
             if (!closed.get()) throw e;
         } finally {
             consumer.close();
         }
     }

     // Shutdown hook which can be called from a separate thread
     public void shutdown() {
         closed.set(true);
         consumer.wakeup();
     }
 }


















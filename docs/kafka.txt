用于构建实时数据管道和流应用，具有水平扩展性，容错性，邪恶的快。发布订阅的消息系统，实时有效的流数据，安全地分布式复制集群。

简介，Kafka是一个分布式流平台。流平台应具有三种关键能力，可以发布订阅记录流，与消息队列或企业消息系统类似。
可以以具有容错性的方式存储记录流。可以处理记录流当它们发生时。

kafka主要用于两广泛类应用，在系统或应用间构建可靠的实时流数据管道。构建实时流应用来转换或响应数据流。

kafka运行于集群模式，集群以topic来区分存储记录流，每个记录由键、值和时间戳组成。

kafka有四种核心API，生产者，允许一个应用发布一到多个topic的记录流。消费者，允许一个应用订阅一到多个topic和处理向它们出示的记录流。
流，允许一个应用充当一个流处理器，从一到多个topic消费一个输入流，产生一个输出流到一到多个输出topic，有效地转换输入流到输出流。
连接器，允许构建和运行可重复使用的生产者或消费者连接kafka的topic到已存在的应用或数据系统，例如，
一个到关系数据库的连接器可以捕获一个表的每次改变。

kafka里客户端和服务器端的通信是采用一个简单、高性能和语言无关的TCP协议。协议具有版本且维护对旧版本的向后兼容。

topic和log，kafka对一个记录流的核心抽象是topic，topic是一个分类或供给名称，记录就发布给它。topic总是多订阅者，
即一个topic可以有零到多个消费者订阅写向它的数据。对于每个topic，集群维护一个分区log，每个分区是一个有序的不可变的记录序列，
且不断地在后面追加，是一个结构化的commit log，分区中的每个记录都被分配一个连续的id号，叫做offset（偏移量）唯一地标识分区中的一条记录。

kafka集群保留所有发布的记录，无论它们是否已经被消费，保留周期的时长是可配置的。如果保留策略设置为两天，记录发布后的两天内都可以被消费，
超期后就会被丢弃来释放空间。kafka的性能在对于数据量大小方面来说永远是高效的，所以存储长时间的数据不是问题。

事实上，每个消费者上仅仅保留的元数据是这个消费者在log中的偏移量或位置，偏移量被消费者控制，通常一个消费者将线性推进它的偏移量当它读记录时，
但是，事实上，消费者可以以任何它喜欢的顺序来消费记录，所以偏移量的变化不一定是线性增长的。
消费者可以重新复位到一个旧的偏移量重新处理过去的数据，或向前跳至最近的记录，从现在开始消费。

kafka的消费者非常cheap，它们来和去在集群上或其它消费者上没有太多冲撞，每个人消费自己的，互不影响。

日志中的分区有几个目的，首先，它允许log在单个服务器上扩展到适合大小，每个分区必须适合装载它的服务器，一个topic可以有很多分区，
所以可以处理任意数量的数据。其次，它充当并行的单元，分区之间并行消费，互不影响。

日志的分区是分布在kafka集群中的服务器上的，每个服务器为一个多分区的共享处理数据和请求。每个分区重复一定的数目用于容错性，该数目可配置。
在重复分区中，其中一个分区所在服务器充当leader，其余的零到多个服务器充当followers，leader处理对该分区的所有读写请求，
而followers被动地复制leader的数据但不处理任何请求，如果leader失败，followers中的一个将自动变为新的leader，
一个服务器对存储在它上面的所有分区中的一些分区充当leader，对剩余的分区充当follower，所以集群中的负载很好地平衡了。

生产者，生产者发布数据到它们选择的topic，生产者承担哪个记录分配给topic中的哪个分区。可以使用简单的轮询的方式达到负载均衡，
或基于某个语义分区函数（如基于记录中的某个key来选择分区）。

消费者，消费者用一个消费者组名称来标记自己，发布到一个topic里的每个记录，被分发到每个订阅的消费者组中的一个消费者实例。
消费者实例可以在不同的进程里或不同的机器上。如果所有的消费者实例都有相同的消费者组名称，记录将在所有的消费者实例上有效地负载均衡。
如果所有的消费者实例的组名都不相同，这时每条记录将广播到所有的消费者实例。

通常情况下发现，所有topic都有很少的消费者组，每个消费者组在逻辑上作为一个订阅者，每个消费者组有许多消费者实例组成用于扩展性和容错性。
这并没有超越发布订阅语义，只不过订阅者是一个消费者集群而不是单个消费者。

kafka中消费方式的实现是在所有的消费者实例上来分割log中的所有分区，所以任何时候每个实例是所有分区的一个公平共享的排它消费者。
这种组内维护成员关系的过程被kafka协议动态处理。如果新实例加入到组将从组内的其它成员那接任一些分区，如果一个实例挂了，
它的分区将分发给剩余的实例。

kafka只提供一个分区里面记录的总顺序，同一个topic的不同分区间无法做到。对于分区数据来说，
每个分区顺序联合的能力通过key来实现对大多数应用是足够的。如果想要一个topic的所有的记录的一个总顺序，这时一个topic只能有一个分区，
同时一个消费者组里只能有一个消费者实例。

保证，kafka在一个高级别提供一下保证，一个生产者发送给一个特定topic分区的所有消息将以它们被发送的顺序追加到后面。先发送记录1再发送记录2，
那么在log的分区中记录1偏移量小且先出现。一个消费者以log中记录存储的顺序查看它们。对于一个具有复制因子为N的topic，
我们将容忍最多N-1个服务器失败而不会丢失log中的任何已提交记录。

作为一个消息系统，kafka的流概念如何和传统企业的消息系统比较。传统消息有两类模型，队列和发布订阅。在队列模式中，
一个消费者池中的所有消费者可以从一个服务器上读数据，每个记录最终到其中一个消费者。在发布订阅模式中，每个记录将广播给所有的消费者，
即每个消费者都会消费所有的记录。每个模型都有自己的长处和不足。队列模型的长处是允许在多个消费者实例上分割对数据的处理，
这样可以扩展处理能力。不幸的是，队列不是多订阅者的，一旦一个消费者读取了数据，数据就不存在了。发布订阅允许广播数据到多个消费者，
但是没有办法处理扩展能力，因为每条消息到每个订阅者。

kafka中消费者组的概念泛化为两个概念。对于一个队列，消费者组就是一个消费者的集合，在它上面分割对数据的处理。
对于发布订阅，允许广播数据到多个消费者组。kafka模型的优势是每个topic都有以上两个属性，能够扩展处理能力，同时也是多订阅者的。
且比传统的消息系统具有更强的顺序保证。

在传统的队列中，记录在服务器上的存储是有序的，多个消费者从队列消费时，服务器以记录存储的顺序交出记录，但是记录是异步地分发给消费者的，
所以当它们到达不同消费者时顺序将变乱。实际意味着在并行消费情况下记录顺序的丢失。消息系统通常使用一个概念来绕过这个问题，就是独占消费，
只允许一个消费者从一个队列消费，不过同时并行消费也已经不存在了。

kafka做的更好，通过一个并行的概念--分区（在topic里）。能够同时提供顺序保证和负载均衡在一池消费者上。
实现为把topic里的所有分区分配给消费者组中的所有消费者，以至于topic中的每个分区实际上被消费者组内的一个确定的消费者在消费。
这样做我们能够确定这个消费者是那个分区唯一的消费者且顺序地消费数据。因为有许多分区，所以在许多消费者实例上任然可以均衡负载。
注意，一个消费者组中的消费者数量不能比分区数目多。

作为一个存储系统，任何消息队列都允许发布消息和消费它们之间解耦，是在有效地为飞行中的消息充当一个存储系统。
kafka的不同之处在于它是一个非常好的存储系统。数据写入kafka就是写入磁盘和重复备份用于容错性。
kafka允许生产者等待回应，以至于一个写入操作不会被认为成功直到数据被复制备份和即使服务器写入失败也要保证持久化。
磁盘结构kafka使用良好扩展，无论服务器上的数据量是KB还是TB，kafka的性能都是一样的好。

由于认知对待存储和允许客户端控制读取数据的位置，可以认为kafka是一类特殊目的的分布式文件系统，专用于高性能、低延时的commit log的存储、复制和传播。

用于流处理，仅仅读、写、存储数据流是不够的，目的是能够进行实时的流处理。kafka的一个流处理器是，可以从输入topic中消费连续不断的数据流，
在这些数据流上执行一些操作处理，生产连续不断的数据流到输出topic。例如，一个零售应用可以消费销售和运输的输入流，
生成根据这些数据计算的重新排序和价格调整的输出流。

可以直接使用生产者和消费者API做一些简单的处理，对于比较复杂的转换kafka提供一个完全集成的流API，这允许构建应用来做些有意义的处理，
像从流上计算聚合或把流连接在一起。这种功能可以解决应用面对的这类型难题，处理无序数据、重新处理输入作为转码，执行有状态的计算。
流API构建在kafka提供的核心基元上，生产者和消费者API用于输入，kafka用于有状态存储，相同的组机制用于在多个流处理器实例间容错。

把以上特性结合起来，把消息、存储和流处理结合起来或许看起来不寻常，但是它对kafka作为流处理平台的角色来说是必须的。
一个分布式文件系统像HDFS允许存储静态文件用于大批量处理。实际上像这样的一个系统允许存储和处理过去的历史数据。
一个传统的企业消息系统允许处理将来的消息就是在你订阅之后将收到。以这种方式构建的应用处理将来的数据当到达时。kafka把这些能力结合起来，
这种结合对于kafka用作流应用的平台和流数据管道来说都是关键的。通过结合存储和低延时订阅，流应用能够以相同的方式对待过去和未来的数据。
这是单个应用能够处理历史存储数据而不是当它到达最后一条数据就结束。这是流处理的一个泛化概念，包括批量处理和消息驱动应用。

同样地像流数据管道，把订阅和实时事件联合起来使kafka可以用于非常低延迟的管道。但可靠存储数据的能力使它可以用于关键数据，
即数据的分发必须得到保证。或与离线系统集成，仅周期性地加载数据。或向下到时间的扩展周期用于维护。流处理功能使它能够转换数据当到达时。

用例
消息，替换传统的消息代理，消息代理的使用有很多原因（把数据的处理和生产分开，缓存未处理的消息），与大多数消息系统相比，
kafka有更好的吞吐量，内建分区、复制和容错，使它成为大规模消息处理应用的一个好的解决方案。
以我们的经验消息使用通常在一个相对较低的吞吐量，但是可能会要求比较小的端到端延时，经常依赖于kafka提供的强壮的持久化保证。

站点活动跟踪，原本用于能够重建一个用户活动跟踪管道，作为一个实时的发布订阅推送的集合。
这意味着站点活动（页面访问，搜索，其它动作等）采用一个活动类型一个topic的形式被发送到中央topics。这些推送对于若干应用情况是可用的，
包括实时处理、实时监控，加载到Hadoop，离线数据存储系统用于离线数据处理和报表。

度量，kafka经常用于运营监控数据，涉及从分布式应用聚合统计来产生运营数据的集中式的推送。

日志聚合，kafka可作为日志聚合方案的一个替代。日志聚合典型地从服务器收集物理日志文件，
把它们放到一个核心的地方（文件服务器或HDFS）来处理。kafka抽象掉了文件的详细内容，给出日志的一个干净抽象，或事件数据作为一个消息流。
这允许更低延时的处理和更容易地支持多数据源和分布式数据消费。与一般的log系统如Scribe或Flume相比，kafka提供同等的好性能，
更强壮的持久化保证（采用复制备份），更低的端到端延时。

流处理，在由多个阶段组成的处理管道里面处理数据，原始的输入数据从kafka的topics消费，然后聚合、浓缩或其它的转化，
然后进入新的topics用于进一步消费或跟踪处理。例如一个处理管道用于推荐新文章，可能从RSS订阅爬取文章内容，把它发布到一个topic，
进一步的处理可能常规化，消除重复，把干净的文章内容发布到另一个新的topic，最终处理可能推荐这些文章给用户。
这样的处理管道创建实时数据流动图基于单个的topic。一个轻量但强大的流处理库在kafka里被提供来执行像上面的那些数据处理。
除了kafka之外还有Apache Storm和Apache Samza流处理工具。

事件源，事件源风格的应用设计为当状态改变时进行记录，产生以时间为顺序的一系列记录。kafka支持非常大量的日志存储，
使它成为这类应用非常优秀的后台。

commit log，kafka可以服务于一个外部的commit log用于分布式系统，日志帮助在节点间复制进行备份，
充当一个重同步机制用于失败的节点来重新存储它们的数据，日志压缩（合并）特性支持这种用法，这种用法与Apache BookKeeper相似。

